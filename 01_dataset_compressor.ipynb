{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "#chose the image size here. Delete the compressed dataset if it has already been generated.\n",
    "#This software will not override an existing compressed dataset.\n",
    "image_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data generator. Can read a dataset of images and masks and can export compressed images.\n",
    "\n",
    "class DataGen():\n",
    "    def __init__(self, ids, path, path2, batch_size=8, image_size=128):\n",
    "        self.ids = ids\n",
    "        self.path = path\n",
    "        self.path2 = path2\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        \n",
    "    def __load__(self, id_name):\n",
    "        ## Path\n",
    "        \n",
    "        image_path = os.path.join(self.path, id_name)\n",
    "\n",
    "        mask_path = os.path.join(self.path2, id_name[:-4] + \"_segmentation.png\")\n",
    "        \n",
    "        ## Reading Images (resize and add padding)\n",
    "        image = cv2.imread(image_path)\n",
    "        h, w = image.shape[:2]\n",
    "        scale_f = self.image_size/max(h,w)\n",
    "        image = cv2.resize(image, (int(round(w*scale_f)), int(round(h*scale_f))))\n",
    "        new_size = image.shape[:2]\n",
    "        delta_w = self.image_size - new_size[1]\n",
    "        delta_h = self.image_size - new_size[0]\n",
    "        top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
    "        left, right = delta_w//2, delta_w-(delta_w//2)\n",
    "        color = [0, 0, 0]\n",
    "        image = cv2.copyMakeBorder(image, top, bottom, left, right, cv2.BORDER_CONSTANT,value=color)\n",
    "        \n",
    "        ## Reading Masks\n",
    "        mask = cv2.imread(mask_path, -1)\n",
    "        \n",
    "        h, w = mask.shape[:2]\n",
    "        scale_f = self.image_size/max(h,w)\n",
    "        mask = cv2.resize(mask, (int(round(w*scale_f)), int(round(h*scale_f))))\n",
    "        new_size = mask.shape[:2]\n",
    "        delta_w = self.image_size - new_size[1]\n",
    "        delta_h = self.image_size - new_size[0]\n",
    "        top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
    "        left, right = delta_w//2, delta_w-(delta_w//2)\n",
    "        color = [0, 0, 0]\n",
    "        mask = cv2.copyMakeBorder(mask, top, bottom, left, right, cv2.BORDER_CONSTANT,value=color)\n",
    "        \n",
    "        mask = np.expand_dims(mask, axis=-1)\n",
    "        mask = np.maximum(mask, mask)\n",
    "\n",
    "        \n",
    "        ## Normalizaing \n",
    "        image = image/255.0\n",
    "        mask = mask/255.0\n",
    "        \n",
    "        return image, mask\n",
    "    \n",
    "    def __saveitem__(self, id_name, location, datatype):\n",
    "        _img, _mask = self.__load__(id_name)\n",
    "        cv2.imwrite('dataset/'+location+'/Segmentazione/'+datatype+'/Input/' + id_name, _img*255)\n",
    "        cv2.imwrite('dataset/'+location+'/Segmentazione/'+datatype+'/GroundTruth/' + id_name[:-4] + \"_segmentation.png\", _mask*255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of training IDs: 2234\n",
      "# of validation IDs: 240\n",
      "# of test IDs: 120\n",
      "Total # of IDs: 2594\n"
     ]
    }
   ],
   "source": [
    "# Select dataset\n",
    "sel_dat = \"Dataset_Nei\"\n",
    "\n",
    "train_path = \"dataset/\" + sel_dat + \"/Segmentazione/ISIC2018_Task1-2_Training_Input\"\n",
    "gt_path = \"dataset/\" + sel_dat + \"/Segmentazione/ISIC2018_Task1_Training_GroundTruth\"\n",
    "\n",
    "# Training Ids\n",
    "img_ids = next(os.walk(train_path))\n",
    "img_ids = img_ids[2:][0]\n",
    "gt_ids = next(os.walk(gt_path))\n",
    "gt_ids = gt_ids[2:][0]\n",
    "random.shuffle(img_ids)\n",
    "\n",
    "img_data_size = len(img_ids)\n",
    "#img_data_size = 100 #Total images to be used size. Comment to use the whole dataset\n",
    "img_ids = img_ids[:img_data_size]\n",
    "\n",
    "## Validation Data Size\n",
    "val_data_size = 24*10\n",
    "train_data_size = len(img_ids)-val_data_size\n",
    "\n",
    "valid_ids = img_ids[:val_data_size]\n",
    "train_ids = img_ids[val_data_size:][:train_data_size]\n",
    "\n",
    "## Test Data Size\n",
    "test_data_size = 12*10\n",
    "train_data_size = len(train_ids)-test_data_size\n",
    "\n",
    "test_ids = train_ids[:test_data_size]\n",
    "train_ids = train_ids[test_data_size:][:train_data_size]\n",
    "\n",
    "print(\"# of training IDs: \" + str(len(train_ids)))\n",
    "print(\"# of validation IDs: \" + str(len(valid_ids)))\n",
    "print(\"# of test IDs: \" + str(len(test_ids)))\n",
    "print(\"Total # of IDs: \" + str(len(img_ids)))\n",
    "\n",
    "gen_train = DataGen(train_ids, train_path, gt_path, batch_size=1, image_size=image_size)\n",
    "gen_valid = DataGen(valid_ids, train_path, gt_path, batch_size=1, image_size=image_size)\n",
    "gen_test = DataGen(test_ids, train_path, gt_path, batch_size=1, image_size=image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the directory tree if it doesn't exist\n",
    "\n",
    "directory = \"dataset/Dataset_compressed_\" + str(image_size)\n",
    "\n",
    "try:\n",
    "    os.stat(directory)\n",
    "except:\n",
    "    os.mkdir(directory)\n",
    "    os.mkdir(directory + \"/Segmentazione\")\n",
    "    os.mkdir(directory + \"/Segmentazione/Training\")\n",
    "    os.mkdir(directory + \"/Segmentazione/Training/Input\")\n",
    "    os.mkdir(directory + \"/Segmentazione/Training/GroundTruth\")\n",
    "    os.mkdir(directory + \"/Segmentazione/Validation\")\n",
    "    os.mkdir(directory + \"/Segmentazione/Validation/Input\")\n",
    "    os.mkdir(directory + \"/Segmentazione/Validation/GroundTruth\")\n",
    "    os.mkdir(directory + \"/Segmentazione/Test\")\n",
    "    os.mkdir(directory + \"/Segmentazione/Test/Input\")\n",
    "    os.mkdir(directory + \"/Segmentazione/Test/GroundTruth\")\n",
    "\n",
    "    #saves a the dataset in the /Dataset_compressed_[size] folder. Size depending on image_size\n",
    "    for i in range(0,len(train_ids)):\n",
    "        if train_ids[i][:-4]+\"_segmentation.png\" in gt_ids:\n",
    "            gen_train.__saveitem__(train_ids[i], \"Dataset_compressed_\" + str(image_size), \"Training\")\n",
    "        else:\n",
    "            text = \"could not save \" + train_ids[i]\n",
    "            #print(train_ids[i])\n",
    "\n",
    "    for i in range(0,len(valid_ids)):\n",
    "        if valid_ids[i][:-4]+\"_segmentation.png\" in gt_ids:\n",
    "            gen_valid.__saveitem__(valid_ids[i], \"Dataset_compressed_\" + str(image_size), \"Validation\")\n",
    "        else:\n",
    "            text = \"could not save \" + valid_ids[i]\n",
    "            #print(valid_ids[i])\n",
    "\n",
    "    for i in range(0,len(test_ids)):\n",
    "        if test_ids[i][:-4]+\"_segmentation.png\" in gt_ids:\n",
    "            gen_valid.__saveitem__(test_ids[i], \"Dataset_compressed_\" + str(image_size), \"Test\")\n",
    "        else:\n",
    "            text = \"could not save \" + test_ids[i]\n",
    "            #print(valid_ids[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
